---
# Ansible Playbook for Azure Databricks Workspace Creation
# Requirements: ansible, azure.azcollection

- name: Create Azure Databricks Workspace with Standard Compute
  hosts: localhost
  connection: local
  gather_facts: false

  vars:
    # Azure Configuration
    resource_group_name: "rg-databricks-pyspark"
    location: "East US"
    workspace_name: "pyspark-databricks-workspace"

    # Pricing Tier Options: 'trial', 'standard', 'premium'
    # trial: Free for 14 days, basic features
    # standard: $0.40/DBU, good for development/basic production
    # premium: $0.55/DBU, enterprise features, security, Unity Catalog
    pricing_tier: "standard"

    # Compute Cluster Configuration
    cluster_name: "pyspark-standard-cluster"
    node_type_id: "Standard_DS3_v2"
    driver_node_type_id: "Standard_DS3_v2"
    min_workers: 1
    max_workers: 3
    autotermination_minutes: 120
    spark_version: "13.3.x-scala2.12"

    # Tags
    common_tags:
      Environment: "Development"
      Project: "PySpark-Examples"
      Owner: "DataTeam"
      Purpose: "Spark-Remote-Compute"

  tasks:
    - name: Create Resource Group
      azure.azcollection.azure_rm_resourcegroup:
        name: "{{ resource_group_name }}"
        location: "{{ location }}"
        tags: "{{ common_tags }}"
        state: present
      register: rg_result

    - name: Create Azure Databricks Workspace
      azure.azcollection.azure_rm_databricks_workspace:
        resource_group: "{{ resource_group_name }}"
        name: "{{ workspace_name }}"
        location: "{{ location }}"
        sku_name: "{{ pricing_tier }}"
        tags: "{{ common_tags }}"
        state: present
      register: databricks_workspace

    - name: Display Workspace Information
      debug:
        msg:
          - "Databricks Workspace Created Successfully!"
          - "Resource Group: {{ resource_group_name }}"
          - "Workspace Name: {{ workspace_name }}"
          - "Location: {{ location }}"
          - "Workspace URL: https://{{ databricks_workspace.workspace_url }}"
          - "Workspace ID: {{ databricks_workspace.workspace_id }}"

    - name: Save Workspace Details to File
      copy:
        content: |
          # Azure Databricks Workspace Details
          # Generated: {{ ansible_date_time.iso8601 }}

          DATABRICKS_WORKSPACE_URL=https://{{ databricks_workspace.workspace_url }}
          DATABRICKS_WORKSPACE_ID={{ databricks_workspace.workspace_id }}
          DATABRICKS_RESOURCE_GROUP={{ resource_group_name }}
          DATABRICKS_WORKSPACE_NAME={{ workspace_name }}
          DATABRICKS_LOCATION={{ location }}

          # Cluster Configuration
          DATABRICKS_CLUSTER_NAME={{ cluster_name }}
          DATABRICKS_NODE_TYPE={{ node_type_id }}
          DATABRICKS_MIN_WORKERS={{ min_workers }}
          DATABRICKS_MAX_WORKERS={{ max_workers }}
          DATABRICKS_SPARK_VERSION={{ spark_version }}
        dest: "./databricks-config.env"
        mode: "0600"

    - name: Create Databricks Configuration for Python
      copy:
        content: |
          """
          Databricks Configuration for PySpark Examples
          Generated by Ansible: {{ ansible_date_time.iso8601 }}
          """

          DATABRICKS_CONFIG = {
              "workspace_url": "https://{{ databricks_workspace.workspace_url }}",
              "workspace_id": "{{ databricks_workspace.workspace_id }}",
              "resource_group": "{{ resource_group_name }}",
              "workspace_name": "{{ workspace_name }}",
              "location": "{{ location }}",
              "cluster_config": {
                  "cluster_name": "{{ cluster_name }}",
                  "node_type_id": "{{ node_type_id }}",
                  "driver_node_type_id": "{{ driver_node_type_id }}",
                  "min_workers": {{ min_workers }},
                  "max_workers": {{ max_workers }},
                  "autotermination_minutes": {{ autotermination_minutes }},
                  "spark_version": "{{ spark_version }}",
                  "enable_elastic_disk": True,
                  "disk_spec": {
                      "disk_type": {
                          "azure_disk_volume_type": "PREMIUM_LRS"
                      },
                      "disk_size": 64
                  }
              }
          }
        dest: "./shared/databricks_config.py"
        mode: "0644"

    - name: Display Next Steps
      debug:
        msg:
          - "ðŸŽ‰ Azure Databricks Workspace Created Successfully!"
          - ""
          - "ðŸ“‹ Next Steps:"
          - "1. Open workspace: https://{{ databricks_workspace.workspace_url }}"
          - "2. Create compute cluster using the cluster playbook:"
          - "   ansible-playbook create-databricks-cluster.yml"
          - "3. Configure authentication (see databricks-auth-setup.yml)"
          - ""
          - "ðŸ’¾ Configuration files created:"
          - "   - databricks-config.env (environment variables)"
          - "   - shared/databricks_config.py (Python configuration)"
          - ""
          - "ðŸ”§ To connect from your PySpark examples:"
          - "   source databricks-config.env"
          - "   # Use DATABRICKS_WORKSPACE_URL in your connection code"
